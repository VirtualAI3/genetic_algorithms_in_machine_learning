# üß¨ Genetic Algorithms in Machine Learning

Este proyecto implementa diferentes aplicaciones de **Algoritmos Gen√©ticos (GA)** en problemas de **aprendizaje autom√°tico**.  
El objetivo es aprovechar el poder de la optimizaci√≥n evolutiva para encontrar mejores configuraciones en modelos de machine learning.

---

## üìå M√≥dulos principales

### üîπ FeatureSelection
Implementa un algoritmo gen√©tico para seleccionar el subconjunto √≥ptimo de caracter√≠sticas, buscando un balance entre rendimiento del modelo y reducci√≥n de dimensionalidad.

Este m√≥dulo implementa un algoritmo Gen√©tico (GA) para la selecci√≥n de caracter√≠sticas en datasets de alta dimensionalidad.

El objetivo es encontrar un subconjunto √≥ptimo de features que maximice el rendimiento de los modelos mientras se minimiza la complejidad (n√∫mero de variables).
‚úÖ Ejemplo de uso:
```python
from feature_selection import GeneticFeatureSelector
import pandas as pd

# Cargar dataset Santander
data = pd.read_csv("archive/santander.csv")
X = data.drop(["target", "ID_code"], axis=1)
y = data["target"]

# Crear selector gen√©tico
selector = GeneticFeatureSelector(
    models=["rf", "xgb", "mlp", "svm", "lr"],
    population_size=20,
    generations=10,
    mutation_rate=0.1,
    alpha=0.05
)

# Ejecutar el proceso
results = selector.run(X, y)

# Exportar resultados
selector.save_results("results_feature_selection.csv")

# Visualizaci√≥n comparativa
selector.plot_results()
```



### üîπ HyperparameterOptimizer
Un optimizador de hiperpar√°metros basado en algoritmos gen√©ticos que permite:
- Explorar espacios de b√∫squeda complejos de par√°metros.
- Soportar par√°metros de tipo **real, discreto y categ√≥rico**.
- Evaluar configuraciones mediante **validaci√≥n cruzada**.
- Utilizar **m√∫ltiples m√©tricas de fitness** (ej: `accuracy`, `f1`, `roc_auc`) y combinarlas con diferentes pesos.
- Reportar la evoluci√≥n de los mejores individuos por generaci√≥n.
- Entrenar y evaluar autom√°ticamente el mejor modelo encontrado.

‚úÖ Ejemplo de uso:
```python
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import f1_score, accuracy_score

param_ranges = {
    'hidden_layer_sizes': ([(50,), (100,), (50,50)], None, 'choice'),
    'activation': (['relu', 'tanh'], None, 'choice'),
    'alpha': (1e-5, 1e-1, 'float')
}

scoring = {
    "f1": (f1_score, 0.6),
    "accuracy": (accuracy_score, 0.4)
}

optimizer = HyperparameterOptimizer(
    model_class=MLPClassifier,
    X=X_train, y=y_train,
    param_ranges=param_ranges,
    scoring=scoring,
    cv_folds=5,
    generations=20
)

best_params = optimizer.optimize()
results = optimizer.evaluate_best_model(X_test, y_test)
````
### üîπ NeuronEvolution
