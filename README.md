# üß¨ Genetic Algorithms in Machine Learning

Este proyecto implementa diferentes aplicaciones de **Algoritmos Gen√©ticos (GA)** en problemas de **aprendizaje autom√°tico**.  
El objetivo es aprovechar el poder de la optimizaci√≥n evolutiva para encontrar mejores configuraciones en modelos de machine learning.

---

## üìå M√≥dulos principales

### üîπ FeatureSelection
Implementa un algoritmo gen√©tico para seleccionar el subconjunto √≥ptimo de caracter√≠sticas, buscando un balance entre rendimiento del modelo y reducci√≥n de dimensionalidad.

Este m√≥dulo implementa un algoritmo Gen√©tico (GA) para la selecci√≥n de caracter√≠sticas en datasets de alta dimensionalidad.

Usa Random Forest, XGBoost, MLP, LightGBM y Logistic Regression.

El objetivo es encontrar un subconjunto √≥ptimo de features que maximice el rendimiento de los modelos mientras se minimiza la complejidad (n√∫mero de variables).

‚úÖ Ejemplo de uso:
```python
from feature_selection import GeneticFeatureSelector
import pandas as pd

# Cargar dataset Santander
data = pd.read_csv("archive/santander.csv")
X = data.drop(["target", "ID_code"], axis=1)
y = data["target"]

# Crear selector gen√©tico
selector = GeneticFeatureSelector(
    models=["rf", "xgb", "mlp", "svm", "lr"],
    population_size=20,
    generations=10,
    mutation_rate=0.1,
    alpha=0.05
)

# Ejecutar el proceso
results = selector.run(X, y)

# Exportar resultados
selector.save_results("results_feature_selection.csv")

# Visualizaci√≥n comparativa
selector.plot_results()
```



### üîπ HyperparameterOptimizer
Un optimizador de hiperpar√°metros basado en algoritmos gen√©ticos que permite:
- Explorar espacios de b√∫squeda complejos de par√°metros.
- Soportar par√°metros de tipo **real, discreto y categ√≥rico**.
- Evaluar configuraciones mediante **validaci√≥n cruzada**.
- Utilizar **m√∫ltiples m√©tricas de fitness** (ej: `accuracy`, `f1`, `roc_auc`) y combinarlas con diferentes pesos.
- Reportar la evoluci√≥n de los mejores individuos por generaci√≥n.
- Entrenar y evaluar autom√°ticamente el mejor modelo encontrado.

‚úÖ Ejemplo de uso:
```python
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import f1_score, accuracy_score

param_ranges = {
    'hidden_layer_sizes': ([(50,), (100,), (50,50)], None, 'choice'),
    'activation': (['relu', 'tanh'], None, 'choice'),
    'alpha': (1e-5, 1e-1, 'float')
}

scoring = {
    "f1": (f1_score, 0.6),
    "accuracy": (accuracy_score, 0.4)
}

optimizer = HyperparameterOptimizer(
    model_class=MLPClassifier,
    X=X_train, y=y_train,
    param_ranges=param_ranges,
    scoring=scoring,
    cv_folds=5,
    generations=20
)

best_params = optimizer.optimize()
results = optimizer.evaluate_best_model(X_test, y_test)
````
### üîπ NeuronEvolution
Implementa un algoritmo gen√©tico para seleccionar la arquitectura √≥ptima de una CNN sobre el dataset CIFAR-10.
Busca un balance entre rendimiento (accuracy) y complejidad (n√∫mero de capas).

El m√≥dulo entrena y eval√∫a arquitecturas candidatas en un subconjunto reducido del dataset para acelerar la b√∫squeda, y al finalizar entrena el mejor modelo sobre todo el dataset y lo eval√∫a en el conjunto de test.

Modelos generados: CNNs personalizadas con diferentes configuraciones de capas convolucionales, fully connected, activaciones y dropout.
‚úÖ Ejemplo de uso:
```python
from cnn_evolution import EvolvedCNNSelector

# Crear el selector gen√©tico
selector = EvolvedCNNSelector(
    population_size=20,       # tama√±o de la poblaci√≥n
    generations=12,           # n√∫mero de generaciones
    tournament_size=3,        # tama√±o del torneo para selecci√≥n
    elitism=2,                # n√∫mero de mejores individuos que pasan directo
    crossover_prob=0.9,       # probabilidad de cruce
    mutation_prob=0.3,        # probabilidad de mutaci√≥n
    eval_epochs=3,            # √©pocas r√°pidas para fitness
    final_epochs=10,          # entrenamiento final del mejor modelo
    device="cuda"             # "cuda" o "cpu"
)

# Ejecutar el proceso evolutivo en CIFAR-10
best_model, test_acc = selector.run()

print("Precisi√≥n final en test:", test_acc)
````
