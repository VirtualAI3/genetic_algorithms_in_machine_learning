# üß¨ Genetic Algorithms in Machine Learning

Este proyecto implementa diferentes aplicaciones de **Algoritmos Gen√©ticos (GA)** en problemas de **aprendizaje autom√°tico**.  
El objetivo es aprovechar el poder de la optimizaci√≥n evolutiva para encontrar mejores configuraciones en modelos de machine learning.

---

## üìå M√≥dulos principales

### üîπ FeatureSelection
Implementa un algoritmo gen√©tico para seleccionar el subconjunto √≥ptimo de caracter√≠sticas, buscando un balance entre rendimiento del modelo y reducci√≥n de dimensionalidad.

### üîπ HyperparameterOptimizer
Un optimizador de hiperpar√°metros basado en algoritmos gen√©ticos que permite:
- Explorar espacios de b√∫squeda complejos de par√°metros.
- Soportar par√°metros de tipo **real, discreto y categ√≥rico**.
- Evaluar configuraciones mediante **validaci√≥n cruzada**.
- Utilizar **m√∫ltiples m√©tricas de fitness** (ej: `accuracy`, `f1`, `roc_auc`) y combinarlas con diferentes pesos.
- Reportar la evoluci√≥n de los mejores individuos por generaci√≥n.
- Entrenar y evaluar autom√°ticamente el mejor modelo encontrado.

‚úÖ Ejemplo de uso:
```python
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import f1_score, accuracy_score

param_ranges = {
    'hidden_layer_sizes': ([(50,), (100,), (50,50)], None, 'choice'),
    'activation': (['relu', 'tanh'], None, 'choice'),
    'alpha': (1e-5, 1e-1, 'float')
}

scoring = {
    "f1": (f1_score, 0.6),
    "accuracy": (accuracy_score, 0.4)
}

optimizer = HyperparameterOptimizer(
    model_class=MLPClassifier,
    X=X_train, y=y_train,
    param_ranges=param_ranges,
    scoring=scoring,
    cv_folds=5,
    generations=20
)

best_params = optimizer.optimize()
results = optimizer.evaluate_best_model(X_test, y_test)
````
### üîπ NeuronEvolution